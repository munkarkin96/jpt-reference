{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('OSM_training_data/ensemble_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()\n",
    "\n",
    "cat_dict = {0:'ADULT', 1:'COUNTERFEIT', 2:'LEGIT', 3:'PHARMA', 4:'SMOKE', 5:'TMS', 6:'WEAPON'}\n",
    "dataset['category_number'] = dataset['category_number'].map(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>bodytxt</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>tagtxt</th>\n",
       "      <th>price</th>\n",
       "      <th>category_number</th>\n",
       "      <th>risk</th>\n",
       "      <th>combinedtxt_noNumSWPunc_morethan2char</th>\n",
       "      <th>combinedtxt</th>\n",
       "      <th>seller_id_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58d3365f3f6f673be6804786</td>\n",
       "      <td>Fat Burners &amp; Thermogenics BLOODSHR3D (WAR EDI...</td>\n",
       "      <td>BLOODSHR3D (WAR EDITION) Ultra Premium Fat Bur...</td>\n",
       "      <td>53665695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>282.84</td>\n",
       "      <td>LEGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>Fat Burners Thermogenics BLOODSHRD WAR EDITION...</td>\n",
       "      <td>Fat Burners &amp; Thermogenics BLOODSHR3D (WAR EDI...</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58d33f023f6f673be68083ee</td>\n",
       "      <td>Vitamins Hylands Cell Salts #12 Silicea 30X Ta...</td>\n",
       "      <td>Hyland's Cell Salts #12 Silicea 30X Tablets, N...</td>\n",
       "      <td>53665695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.88</td>\n",
       "      <td>LEGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>Vitamins Hylands Cell Salts Silicea Tablets Na...</td>\n",
       "      <td>Vitamins Hylands Cell Salts #12 Silicea 30X Ta...</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58d342283f6f673be680a84e</td>\n",
       "      <td>Vitamins Biotics Research - Detoxification 4oz</td>\n",
       "      <td>Biotics Research - Detoxification 4oz Product ...</td>\n",
       "      <td>53665695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.77</td>\n",
       "      <td>LEGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>Vitamins Biotics Research Detoxification Bioti...</td>\n",
       "      <td>Vitamins Biotics Research - Detoxification 4oz...</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>58d39b683f6f673be680f255</td>\n",
       "      <td>HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...</td>\n",
       "      <td>HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...</td>\n",
       "      <td>53889844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492.20</td>\n",
       "      <td>LEGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>HEWLETT PACKARD Toner Page Yield Black Clear S...</td>\n",
       "      <td>HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...</td>\n",
       "      <td>[563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>58d4862b3f6f673be6813014</td>\n",
       "      <td>Herbal Supplements Natural Natural Blood Press...</td>\n",
       "      <td>Natural Blood Pressure Supplement: Blood Press...</td>\n",
       "      <td>53665695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.52</td>\n",
       "      <td>LEGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>Herbal Supplements Natural Natural Blood Press...</td>\n",
       "      <td>Herbal Supplements Natural Natural Blood Press...</td>\n",
       "      <td>[526]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                        id  \\\n",
       "0           0      0  58d3365f3f6f673be6804786   \n",
       "1           1      1  58d33f023f6f673be68083ee   \n",
       "2           2      2  58d342283f6f673be680a84e   \n",
       "3           3      3  58d39b683f6f673be680f255   \n",
       "4           4      4  58d4862b3f6f673be6813014   \n",
       "\n",
       "                                                name  \\\n",
       "0  Fat Burners & Thermogenics BLOODSHR3D (WAR EDI...   \n",
       "1  Vitamins Hylands Cell Salts #12 Silicea 30X Ta...   \n",
       "2     Vitamins Biotics Research - Detoxification 4oz   \n",
       "3  HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...   \n",
       "4  Herbal Supplements Natural Natural Blood Press...   \n",
       "\n",
       "                                             bodytxt  seller_id tagtxt  \\\n",
       "0  BLOODSHR3D (WAR EDITION) Ultra Premium Fat Bur...   53665695    NaN   \n",
       "1  Hyland's Cell Salts #12 Silicea 30X Tablets, N...   53665695    NaN   \n",
       "2  Biotics Research - Detoxification 4oz Product ...   53665695    NaN   \n",
       "3  HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...   53889844    NaN   \n",
       "4  Natural Blood Pressure Supplement: Blood Press...   53665695    NaN   \n",
       "\n",
       "    price category_number  risk  \\\n",
       "0  282.84           LEGIT     1   \n",
       "1  145.88           LEGIT     1   \n",
       "2  248.77           LEGIT     1   \n",
       "3  492.20           LEGIT     1   \n",
       "4  233.52           LEGIT     1   \n",
       "\n",
       "               combinedtxt_noNumSWPunc_morethan2char  \\\n",
       "0  Fat Burners Thermogenics BLOODSHRD WAR EDITION...   \n",
       "1  Vitamins Hylands Cell Salts Silicea Tablets Na...   \n",
       "2  Vitamins Biotics Research Detoxification Bioti...   \n",
       "3  HEWLETT PACKARD Toner Page Yield Black Clear S...   \n",
       "4  Herbal Supplements Natural Natural Blood Press...   \n",
       "\n",
       "                                         combinedtxt seller_id_indices  \n",
       "0  Fat Burners & Thermogenics BLOODSHR3D (WAR EDI...             [526]  \n",
       "1  Vitamins Hylands Cell Salts #12 Silicea 30X Ta...             [526]  \n",
       "2  Vitamins Biotics Research - Detoxification 4oz...             [526]  \n",
       "3  HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...             [563]  \n",
       "4  Herbal Supplements Natural Natural Blood Press...             [526]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.drop_duplicates(subset='name')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fat Burners &amp; Thermogenics BLOODSHR3D (WAR EDI...</td>\n",
       "      <td>LEGIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vitamins Hylands Cell Salts #12 Silicea 30X Ta...</td>\n",
       "      <td>LEGIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vitamins Biotics Research - Detoxification 4oz</td>\n",
       "      <td>LEGIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...</td>\n",
       "      <td>LEGIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herbal Supplements Natural Natural Blood Press...</td>\n",
       "      <td>LEGIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name category_number\n",
       "0  Fat Burners & Thermogenics BLOODSHR3D (WAR EDI...           LEGIT\n",
       "1  Vitamins Hylands Cell Salts #12 Silicea 30X Ta...           LEGIT\n",
       "2     Vitamins Biotics Research - Detoxification 4oz           LEGIT\n",
       "3  HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...           LEGIT\n",
       "4  Herbal Supplements Natural Natural Blood Press...           LEGIT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features = ['name', 'bodytxt', 'tagtxt', 'price', 'category_number', 'combinedtxt_noNumSWPunc_morethan2char']\n",
    "features = ['name', \"category_number\"]\n",
    "df = data[features]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karkin.mun/environments/ml_dir/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fat Burners &amp; Thermogenics BLOODSHR3D (WAR EDI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vitamins Hylands Cell Salts #12 Silicea 30X Ta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vitamins Biotics Research - Detoxification 4oz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herbal Supplements Natural Natural Blood Press...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  category_number\n",
       "0  Fat Burners & Thermogenics BLOODSHR3D (WAR EDI...                2\n",
       "1  Vitamins Hylands Cell Salts #12 Silicea 30X Ta...                2\n",
       "2     Vitamins Biotics Research - Detoxification 4oz                2\n",
       "3  HEWLETT-PACKARD C3903A Toner 4000 Page-Yield B...                2\n",
       "4  Herbal Supplements Natural Natural Blood Press...                2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict_reverse = {'ADULT':0, 'COUNTERFEIT':1, 'LEGIT':2, 'PHARMA':3, 'SMOKE':4,'TMS':5, 'WEAPON':6}\n",
    "df['category_number'] = df['category_number'].map(cat_dict_reverse)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['name'].values\n",
    "labels = df['category_number'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_Y = encoder.transform(labels)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "# pad documents to a max length of 250 words \n",
    "max_length = 250\n",
    "# using Keras's built in pad_sequences \n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44379, 250), (11095, 250), (44379, 7), (11095, 7))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 250, 100)     3529500     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 250, 1528)    5286880     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 250, 1)       1529        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 250)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 250)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1528, 250)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 250, 1528)    0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 250, 1528)    0           bidirectional_1[0][0]            \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1528)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7)            10703       lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,828,612\n",
      "Trainable params: 5,299,112\n",
      "Non-trainable params: 3,529,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Bidirectional, RepeatVector, Permute, Multiply, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K \n",
    "\n",
    "\"\"\"\n",
    "keras.layers.Permute(dims)\n",
    "Permutes the dimensions of the input according to a given pattern.\n",
    "\n",
    "Example\n",
    "-------\n",
    "\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "# Reference\n",
    "# ---------\n",
    "# https://www.youtube.com/watch?v=oaV_Fv5DwUM&t=7s\n",
    "\n",
    "#model = Sequential()\n",
    "word_dim = 100 \n",
    "\n",
    "seq_input = Input(shape = (max_length, ), dtype = 'int32')\n",
    "e = Embedding(vocab_size, word_dim, weights=[embedding_matrix], input_length=250, trainable=False)(seq_input)\n",
    "activations = Bidirectional(LSTM(764, return_sequences = True))(e)\n",
    "\n",
    "\n",
    "## --- Attention Mecchanism -----\n",
    "attention = Dense(1, activation = \"tanh\")(activations)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(764 * 2)(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "\n",
    "sent_rep = Multiply()([activations, attention])\n",
    "sent_rep = Lambda(lambda xin: K.sum(xin, axis = -2), output_shape = (764 * 2, ))(sent_rep)\n",
    "\n",
    "## --- Attention Mecchanism -----\n",
    "\n",
    "model = Dense(len(y[0]), activation = 'softmax')(sent_rep)\n",
    "\n",
    "model = Model(inputs = seq_input, outputs = model)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience = 5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44379 samples, validate on 11095 samples\n",
      "Epoch 1/50\n",
      "44379/44379 [==============================] - 6881s 155ms/step - loss: 0.3358 - acc: 0.8882 - val_loss: 0.2200 - val_acc: 0.9207\n",
      "Epoch 2/50\n",
      "44379/44379 [==============================] - 9733s 219ms/step - loss: 0.1701 - acc: 0.9404 - val_loss: 0.1508 - val_acc: 0.9478\n",
      "Epoch 3/50\n",
      "44379/44379 [==============================] - 9697s 219ms/step - loss: 0.1228 - acc: 0.9574 - val_loss: 0.1296 - val_acc: 0.9558\n",
      "Epoch 4/50\n",
      "44379/44379 [==============================] - 9778s 220ms/step - loss: 0.0982 - acc: 0.9666 - val_loss: 0.1207 - val_acc: 0.9603\n",
      "Epoch 5/50\n",
      "44379/44379 [==============================] - 9676s 218ms/step - loss: 0.0741 - acc: 0.9740 - val_loss: 0.1075 - val_acc: 0.9639\n",
      "Epoch 6/50\n",
      "44379/44379 [==============================] - 9670s 218ms/step - loss: 0.0640 - acc: 0.9779 - val_loss: 0.1156 - val_acc: 0.9620\n",
      "Epoch 7/50\n",
      "44379/44379 [==============================] - 9706s 219ms/step - loss: 0.0425 - acc: 0.9852 - val_loss: 0.1270 - val_acc: 0.9608\n",
      "Epoch 8/50\n",
      "44379/44379 [==============================] - 9845s 222ms/step - loss: 0.0301 - acc: 0.9897 - val_loss: 0.1230 - val_acc: 0.9655\n",
      "Epoch 9/50\n",
      "44379/44379 [==============================] - 9860s 222ms/step - loss: 0.0238 - acc: 0.9919 - val_loss: 0.1302 - val_acc: 0.9664\n",
      "Epoch 10/50\n",
      "44379/44379 [==============================] - 9742s 220ms/step - loss: 0.0198 - acc: 0.9935 - val_loss: 0.1522 - val_acc: 0.9630\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data =(X_test, y_test), epochs=50, verbose=1, callbacks = [es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b97ef68f09a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# y_pred = model.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test_int\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "# y_pred = model.predict(X_test)\n",
    "y_test_int =np.argmax(y_test, axis=1)\n",
    "\n",
    "f1_score(y_test_int, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = ['ADULT', 'COUNTERFEIT', 'LEGIT', 'PHARMA', 'SMOKE', 'TMS', 'WEAPON']\n",
    "print(classification_report(y_test_int, y_pred, target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('glove_50_biLSTM_attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('glove_50_biLSTM_attention.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
