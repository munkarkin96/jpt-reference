{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47150, 64, 64, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pristine_data = np.load('sample_pristine_np.npy')\n",
    "\n",
    "pristine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46235, 64, 64, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data = np.load('sample_fakes_np.npy')\n",
    "\n",
    "fake_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 131201    \n",
      "=================================================================\n",
      "Total params: 14,845,889\n",
      "Trainable params: 2,491,009\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_model(1).h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = model.layers[0].predict(pristine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47150, 2, 2, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_flattened = feature.reshape(-1, 2*2*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47150, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_flattened_pristine = feature_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_feature = model.layers[0].predict(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_flattened_fake = fake_feature.reshape(-1, 2*2*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vgg16_stride16_fake_features.pickle', 'rb') as f:\n",
    "    feature_flattened_fake = pickle.load(f)\n",
    "    \n",
    "with open('vgg16_stride16_pristine_features.pickle', 'rb') as f:\n",
    "    feature_flattened_pristine = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try One-Class SVM using VGG16 features directly without compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.007, kernel='rbf',\n",
       "            max_iter=-1, nu=0.0005, random_state=None, shrinking=True,\n",
       "            tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.OneClassSVM(kernel='rbf', nu=0.0005,gamma=0.007)\n",
    "model.fit(feature_flattened_pristine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18535, 47150, 0.3931071049840933)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model.predict(feature_flattened_pristine)\n",
    "\n",
    "sum(y_train_pred == 1 ), len(y_train_pred), sum(y_train_pred == 1 )/len(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47150, 2048), (46235, 2, 2, 512))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_flattened_pristine.shape, feature_flattened_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 46235, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(feature_flattened_fake.reshape(-1, 2*2*512))\n",
    "\n",
    "sum(y_test_pred == 1 ), len(y_test_pred), sum(y_test_pred == 1 )/len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"vgg16_stride16_fake_features.pickle\", \"wb\") as f:\n",
    "    pickle.dump(fake_feature, f)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "num_features = feature_flattened.shape[1]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(num_features,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(512, activation='relu')(input_img)\n",
    "encoded = Dense(100, activation='relu')(encoded)\n",
    "#encoded = Dense(2000, activation='relu')(encoded)\n",
    "\n",
    "\n",
    "encoded = Dense(50, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(100, activation='relu')(encoded)\n",
    "# decoded = Dense(2000, activation='relu')(decoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(num_features)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#estop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37720, 2048), (9430, 2048))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_cv = train_test_split(feature_flattened, train_size = 0.8, shuffle = True)\n",
    "\n",
    "x_train.shape, x_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37720 samples, validate on 9430 samples\n",
      "Epoch 1/500\n",
      "37720/37720 [==============================] - 4s 107us/step - loss: 26.7321 - val_loss: 29.9329\n",
      "Epoch 2/500\n",
      "37720/37720 [==============================] - 4s 95us/step - loss: 26.7224 - val_loss: 29.9501\n",
      "Epoch 3/500\n",
      "37720/37720 [==============================] - 4s 105us/step - loss: 26.6834 - val_loss: 29.9336\n",
      "Epoch 4/500\n",
      "37720/37720 [==============================] - 4s 93us/step - loss: 26.6692 - val_loss: 29.8987\n",
      "Epoch 5/500\n",
      "37720/37720 [==============================] - 3s 92us/step - loss: 26.6628 - val_loss: 29.8863\n",
      "Epoch 6/500\n",
      "37720/37720 [==============================] - 3s 91us/step - loss: 26.6414 - val_loss: 29.8876\n",
      "Epoch 7/500\n",
      "37720/37720 [==============================] - 3s 88us/step - loss: 26.5885 - val_loss: 29.8430\n",
      "Epoch 8/500\n",
      "37720/37720 [==============================] - 3s 81us/step - loss: 26.5651 - val_loss: 29.8542\n",
      "Epoch 9/500\n",
      "37720/37720 [==============================] - 3s 79us/step - loss: 26.5558 - val_loss: 29.8500\n",
      "Epoch 10/500\n",
      "37720/37720 [==============================] - 3s 86us/step - loss: 26.5519 - val_loss: 29.8298\n",
      "Epoch 11/500\n",
      "37720/37720 [==============================] - 4s 95us/step - loss: 26.5316 - val_loss: 29.8631\n",
      "Epoch 12/500\n",
      "37720/37720 [==============================] - 4s 109us/step - loss: 26.5409 - val_loss: 29.8072\n",
      "Epoch 13/500\n",
      "37720/37720 [==============================] - 4s 105us/step - loss: 26.5099 - val_loss: 29.7944\n",
      "Epoch 14/500\n",
      "37720/37720 [==============================] - 4s 96us/step - loss: 26.4945 - val_loss: 29.7644\n",
      "Epoch 15/500\n",
      "37720/37720 [==============================] - 4s 104us/step - loss: 26.4623 - val_loss: 29.7884\n",
      "Epoch 16/500\n",
      "37720/37720 [==============================] - 4s 98us/step - loss: 26.4411 - val_loss: 29.8317\n",
      "Epoch 17/500\n",
      "37720/37720 [==============================] - 4s 94us/step - loss: 26.4401 - val_loss: 29.7478\n",
      "Epoch 18/500\n",
      "37720/37720 [==============================] - 3s 91us/step - loss: 26.4305 - val_loss: 29.7901\n",
      "Epoch 19/500\n",
      "37720/37720 [==============================] - 3s 89us/step - loss: 26.3787 - val_loss: 29.7610\n",
      "Epoch 20/500\n",
      "37720/37720 [==============================] - 3s 81us/step - loss: 26.3948 - val_loss: 29.7877\n",
      "Epoch 21/500\n",
      "37720/37720 [==============================] - 3s 78us/step - loss: 26.3940 - val_loss: 29.8364\n",
      "Epoch 22/500\n",
      "37720/37720 [==============================] - 3s 85us/step - loss: 26.3806 - val_loss: 29.7642\n",
      "Epoch 23/500\n",
      "37720/37720 [==============================] - 4s 98us/step - loss: 26.3252 - val_loss: 29.6893\n",
      "Epoch 24/500\n",
      "37720/37720 [==============================] - 4s 108us/step - loss: 26.2732 - val_loss: 29.6764\n",
      "Epoch 25/500\n",
      "37720/37720 [==============================] - 4s 102us/step - loss: 26.2670 - val_loss: 29.6986\n",
      "Epoch 26/500\n",
      "37720/37720 [==============================] - 4s 95us/step - loss: 26.2859 - val_loss: 29.6920\n",
      "Epoch 27/500\n",
      "37720/37720 [==============================] - 4s 99us/step - loss: 26.2407 - val_loss: 29.6696\n",
      "Epoch 28/500\n",
      "37720/37720 [==============================] - 4s 97us/step - loss: 26.2249 - val_loss: 29.6804\n",
      "Epoch 29/500\n",
      "37720/37720 [==============================] - 4s 98us/step - loss: 26.2501 - val_loss: 29.7072\n",
      "Epoch 30/500\n",
      "37720/37720 [==============================] - 3s 91us/step - loss: 26.2374 - val_loss: 29.6299\n",
      "Epoch 31/500\n",
      "37720/37720 [==============================] - 3s 89us/step - loss: 26.1934 - val_loss: 29.6492\n",
      "Epoch 32/500\n",
      "37720/37720 [==============================] - 3s 80us/step - loss: 26.1557 - val_loss: 29.5999\n",
      "Epoch 33/500\n",
      "37720/37720 [==============================] - 3s 79us/step - loss: 26.1519 - val_loss: 29.6447\n",
      "Epoch 34/500\n",
      "37720/37720 [==============================] - 3s 86us/step - loss: 26.1379 - val_loss: 29.6710\n",
      "Epoch 35/500\n",
      "37720/37720 [==============================] - 4s 98us/step - loss: 26.1321 - val_loss: 29.5780\n",
      "Epoch 36/500\n",
      "37720/37720 [==============================] - 4s 110us/step - loss: 26.1469 - val_loss: 29.6431\n",
      "Epoch 37/500\n",
      "37720/37720 [==============================] - 4s 103us/step - loss: 26.1373 - val_loss: 29.6323\n",
      "Epoch 38/500\n",
      "37720/37720 [==============================] - 4s 97us/step - loss: 26.0894 - val_loss: 29.6040\n",
      "Epoch 39/500\n",
      "37720/37720 [==============================] - 4s 106us/step - loss: 26.0670 - val_loss: 29.5495\n",
      "Epoch 40/500\n",
      "37720/37720 [==============================] - 4s 98us/step - loss: 26.0440 - val_loss: 29.6399\n",
      "Epoch 41/500\n",
      "37720/37720 [==============================] - 4s 96us/step - loss: 26.0509 - val_loss: 29.5734\n",
      "Epoch 42/500\n",
      "37720/37720 [==============================] - 3s 89us/step - loss: 26.0142 - val_loss: 29.5526\n",
      "Epoch 43/500\n",
      "37720/37720 [==============================] - 3s 92us/step - loss: 26.0291 - val_loss: 29.6117\n",
      "Epoch 44/500\n",
      "37720/37720 [==============================] - 3s 82us/step - loss: 26.0511 - val_loss: 29.5825\n",
      "Epoch 45/500\n",
      "37720/37720 [==============================] - 3s 78us/step - loss: 26.0129 - val_loss: 29.5585\n",
      "Epoch 00045: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38e639a6a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "earlystopper = EarlyStopping(patience=6, verbose=1) \n",
    "# checkpointer = ModelCheckpoint('autoencoder.h5', verbose=1, save_best_only=True)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "class ImageSaver(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        if epoch % 5 == 0:\n",
    "            #encoded_imgs = encoder.predict(X_cv_flattened[0:2])\n",
    "            #decoded_imgs = decoder.predict(encoded_imgs)\n",
    "            decoded_imgs = autoencoder.predict(X_cv_flattened[0:2])\n",
    "            \n",
    "            plt.imsave('img/track_1_%d.png' % (epoch), decoded_imgs[0].reshape(64, 64, 3))\n",
    "            plt.imsave('img/track_2_%d.png' % (epoch), decoded_imgs[1].reshape(64, 64, 3))\n",
    "            \n",
    "        #logging.info(\"Epoch: {}\".format(epoch))\n",
    "\n",
    "        \n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=2048,\n",
    "                validation_data=(x_cv, x_cv),\n",
    "                callbacks=[earlystopper])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"AE_using_feature_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using features extracted from VGG16, and then compressed using Auto Encoder to dim = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_train_feature = encoder.predict(feature_flattened_pristine)\n",
    "AE_fake_feature = encoder.predict(feature_flattened_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47150, 50), (46235, 50))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_train_feature.shape, AE_fake_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.007, kernel='rbf',\n",
       "            max_iter=-1, nu=0.0005, random_state=None, shrinking=True,\n",
       "            tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.OneClassSVM(kernel='rbf', nu=0.0005,gamma=0.007)\n",
    "model.fit(AE_train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(AE_train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47125, 47150, 0.9994697773064687)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_pred == 1 ), len(y_train_pred), sum(y_train_pred == 1 )/len(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(AE_fake_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46227, 46235, 0.9998269709094841)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_pred == 1 ), len(y_test_pred), sum(y_test_pred == 1 )/len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using features extracted from VGG16, and then compressed using PCA to retain 75% of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=256, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=256)\n",
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403305729385465"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37720, 256), (9430, 256))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed =pca.transform(x_train)\n",
    "x_cv_transformed = pca.transform(x_cv)\n",
    "\n",
    "x_train_transformed.shape, x_cv_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train, x_cv contains only pristine (label = 0) samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.007, kernel='rbf',\n",
       "            max_iter=-1, nu=0.0005, random_state=None, shrinking=True,\n",
       "            tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.OneClassSVM(kernel='rbf', nu=0.0005,gamma=0.007)\n",
    "model.fit(x_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18577, 19143)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_pred == 1), sum(y_train_pred == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make some tampered samples to test, and name is x_test \n",
    "\n",
    "EDIT: turns out there's no point because the percentage is almost 50: 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = fake_data[:50]\n",
    "x_test_transformed = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
